{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "それでは学習を始めましょう。まず、XGBoost のコンテナの場所を取得します。コンテナ自体は SageMaker 側で用意されているので、場所を指定すれば利用可能です。\n",
    "\n",
    "まずは、データの前処理でS3に保存したファイルのパスを取得します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls s3://###sagemaker default bucket###/xgboost-churn-stepfunctions/xgboost-churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "prefix = 'xgboost-churn-stepfunctions/xgboost-churn'\n",
    "sagemaker.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記セルを実行して、SageMaker Python SDK Version が 1.xx.x の場合、以下のセルのコメントアウトを解除してから実行してください。実行が完了したら、上にあるメニューから [Kernel] -> [Restart kernel] を選択してカーネルを再起動してください。\n",
    "\n",
    "再起動が完了したら、このノートブックの一番上のセルから再度実行してください。その場合、以下のセルを実行する必要はありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U --quiet \"sagemaker==2.16.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前処理データをダウンロード\n",
    "# s3 = boto3.resource('s3')\n",
    "# s3.Bucket(bucket).download_file('{}/{}'.format(prefix, 'train.csv'), 'train.csv')\n",
    "# s3.Bucket(bucket).download_file('{}/{}'.format(prefix, 'validation.csv'), 'validation.csv')\n",
    "# s3.Bucket(bucket).download_file('{}/{}'.format(prefix, 'test.csv'), 'test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "開発時に学習で利用する場所にデータをアップロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習用データとしてアップロード\n",
    "input_train = sess.upload_data(path='train.csv', key_prefix='xgboost-churn-stepfunctions/xgboost-churn-input')\n",
    "input_validation = sess.upload_data(path='validation.csv', key_prefix='xgboost-churn-stepfunctions/xgboost-churn-input')\n",
    "input_test = sess.upload_data(path='validation.csv', key_prefix='xgboost-churn-stepfunctions/xgboost-churn-input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.session import s3_input\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "input_train_prefix = 's3://{}/{}/train'.format(bucket, 'xgboost-churn-stepfunctions/xgboost-churn-input')\n",
    "input_validation_prefix = 's3://{}/{}/validation'.format(bucket, 'xgboost-churn-stepfunctions/xgboost-churn-input')\n",
    "\n",
    "content_type='text/csv'\n",
    "s3_input_train = TrainingInput(input_train_prefix, content_type=content_type)\n",
    "s3_input_validation = TrainingInput(input_validation_prefix, content_type=content_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "container = sagemaker.image_uris.retrieve(\"xgboost\", boto3.Session().region_name, \"1.2-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "print(s3_output_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習のためにハイパーパラメータを指定したり、学習のインスタンスの数やタイプを指定することができます。XGBoost における主要なハイパーパラメータは以下のとおりです。\n",
    "\n",
    "- max_depth アルゴリズムが構築する木の深さをコントロールします。深い木はより学習データに適合しますが、計算も多く必要で、overfiting になる可能性があります。たくさんの浅い木を利用するか、少数の深い木を利用するか、モデルの性能という面ではトレードオフがあります。\n",
    "- subsample 学習データのサンプリングをコントロールします。これは overfitting のリスクを減らしますが、小さすぎるとモデルのデータが不足してしまいます。\n",
    "- num_round ブースティングを行う回数をコントロールします。以前のイテレーションで学習したときの残差を、以降のモデルにどこまで利用するかどうかを決定します。多くの回数を指定すると学習データに適合しますが、計算も多く必要で、overfiting になる可能性があります。\n",
    "- eta 各ブースティングの影響の大きさを表します。大きい値は保守的なブースティングを行います。\n",
    "- gamma ツリーの成長の度合いをコントロールします。大きい値はより保守的なモデルを生成します。\n",
    "\n",
    "XGBoostのhyperparameterに関する詳細は github もチェックしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\"max_depth\":\"5\",\n",
    "                        \"eta\":\"0.2\",\n",
    "                        \"gamma\":\"4\",\n",
    "                        \"min_child_weight\":\"6\",\n",
    "                        \"subsample\":\"0.8\",\n",
    "                        \"objective\":\"binary:logistic\",\n",
    "                        \"num_round\":\"100\"}\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    hyperparameters=hyperparameters,\n",
    "                                    instance_count=1, \n",
    "                                    instance_type='ml.m4.xlarge',\n",
    "                                    sagemaker_session=sess\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SageMaker Endpointを利用して評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor = xgb.deploy(initial_instance_count = 1, instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在、エンドポイントをホストしている状態で、これを利用して簡単に予測を行うことができます。予測は http の POST の request を送るだけです。 ここではデータを numpy の array の形式で送って、予測を得られるようにしたいと思います。しかし、endpoint は numpy の array を受け取ることはできません。\n",
    "\n",
    "このために、csv_serializer を利用して、csv 形式に変換して送ることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.serializer = sagemaker.serializers.CSVSerializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def predict(data, rows=500):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = ''\n",
    "    for array in split_array:\n",
    "        predictions = ','.join([predictions, xgb_predictor.predict(array).decode('utf-8')])\n",
    "\n",
    "    return np.fromstring(predictions[1:], sep=',')\n",
    "\n",
    "test_data = pd.read_csv('test.csv')\n",
    "dtest = test_data.values\n",
    "predictions = []\n",
    "predictions.append(predict(dtest[:, 1:]))\n",
    "predictions = np.array(predictions).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "機械学習の性能を比較評価する方法はいくつかありますが、単純に、予測値と実際の値を比較しましょう。今回は、顧客が離反する 1 と離反しない 0 を予測しますので、この混同行列を作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=test_data.iloc[:, 0], columns=np.round(predictions), rownames=['actual'], colnames=['predictions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "※ 注意点, アルゴリズムにはランダムな要素があるので結果は必ずしも一致しません.\n",
    "\n",
    "48人の離反者がいて、それらの39名 (true positives) を正しく予測できました。そして、4名の顧客は離反すると予測しましたが、離反していません (false positives)。9名の顧客は離反しないと予測したにもかかわらず離反してしまいました (false negatives)。\n",
    "\n",
    "重要な点として、離反するかどうかを np.round() という関数で、しきい値0.5で判断しています。xgboost が出力する値は0から1までの連続値で、それらを離反する 1 と 離反しない 0 に分類します。しかし、その連続値 (離反する確率) が示すよりも、顧客の離反というのは損害の大きい問題です。つまり離反する確率が低い顧客も、しきい値を0.5から下げて、離反するとみなす必要があるかもしれません。もちろんこては、false positives （離反すると予測したけど離反しなかった）を増やすと思いますが、 true positives (離反すると予測して離反した) を増やし、false negatives (離反しないと予測して離反した）を減らせます。\n",
    "\n",
    "直感的な理解のため、予測結果の連続値をみてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(predictions)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "連続値は0から1まで歪んでいますが、0.1から0.9までの間で、しきい値を調整するにはちょうど良さそうです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "例えば、しきい値を0.5から0.3まで減らしてみたとき、true positives は 1 つ、false positives は 3 つ増え、false negatives は 1 つ減りました。全体からみると小さな値ですが、全体の6-10%の顧客が、しきい値の変更で、予測結果が変わりました。ここで5名にインセンティブを与えることによって、インセンティブのコストが掛かりますが、3名の顧客を引き止めることができるかもしれません。 つまり、最適な閾値を決めることは、実世界の問題を機械学習で解く上で重要なのです。これについてもう少し広く議論し、仮説的なソリューションを考えたいと思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 推論エラーのコストをビジネスモデルから定義"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2値分類の問題においては、しきい値に注意しなければならないという、似たような状況に直面することが多いです。それ自体は問題ではありません。もし、出力の連続値が2クラスで完全に別れていれば、MLを使うことなく単純なルールで解くことができると考えられます。\n",
    "\n",
    "重要なこととして、MLモデルを正版環境に導入する際、モデルが false positives と false negatives に誤って入れたときのコストがあげられます。しきい値の選択は4つの指標に影響を与えます。4つの指標に対して、ビジネス上の相対的なコストを考える必要があるでしょう。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "携帯電話会社の離反の問題において、コストとはなんでしょうか？コストはビジネスでとるべきアクションに結びついています。いくつかの仮定をおいてみましょう。\n",
    "\n",
    "まず、true negatives のコストとして 0USD を割り当てます。満足しているお客様を正しく認識できていれば何も実施しません。\n",
    "\n",
    "false negatives が一番問題で、なぜなら、離反していく顧客を正しく予測できないからです。顧客を失えば、再獲得するまでに多くのコストを払う必要もあり、例えば逸失利益、広告コスト、管理コスト、販売管理コスト、電話の購入補助金などがあります。インターネットを簡単に検索してみると、そのようなコストは数百ドルとも言われ、ここでは 500USD としましょう。これが false negatives に対するコストです。\n",
    "\n",
    "最後に、離反していくと予測された顧客に 100USD のインセンティブを与えることを考えましょう。 携帯電話会社がそういったインセンティブを提供するなら、2回くらいは離反の前に考え直すかもしれません。これは true positive と　false negative のコストになります。false positives の場合 (顧客は満足していて、モデルが誤って離反しそうと予測した場合)、 100USD のインセンティブは捨てることになります。その 100USD を効率よく消費してしまうかもしれませんが、優良顧客へのロイヤリティを増やすという意味では悪くないかもしれません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### コストの計算式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alse negatives が false positives よりもコストが高いことは説明しました。そこで、顧客の数ではなく、コストを最小化するように、しきい値を最適化することを考えましょう。コストの関数は以下のようなものになります。\n",
    "\n",
    "txt\n",
    "500USD * FN(C) + 0USD * TN(C) + 100USD * FP(C) + 100USD * TP(C)\n",
    "FN(C) は false negative の割合で、しきい値Cの関数です。同様にTN, FP, TP も用意します。この関数の値が最小となるようなしきい値Cを探します。 最も単純な方法は、候補となる閾値で何度もシミュレーションをすることです。以下では100個の値に対してループで計算を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs = np.arange(0.01, 1, 0.01)\n",
    "costs = []\n",
    "\n",
    "for c in cutoffs:\n",
    "    _predictions = pd.Categorical(np.where(predictions > c, 1, 0), categories=[0, 1])\n",
    "    matrix_a = np.array([[0, 100], [500, 100]])\n",
    "    matrix_b = pd.crosstab(index=test_data.iloc[:, 0], columns=_predictions, dropna=False)\n",
    "    costs.append(np.sum(np.sum(matrix_a * matrix_b)))\n",
    "\n",
    "costs = np.array(costs)\n",
    "plt.plot(cutoffs, costs)\n",
    "plt.show()\n",
    "print('Cost is minimized near a cutoff of:', cutoffs[np.argmin(costs)], 'for a cost of:', np.min(costs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### エンドポイント の削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### マニュアルで評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = xgb.model_data\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.s3.S3Downloader.download(model_path, './')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar xvzf model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model = pickle.load(open('xgboost-model', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "xgboost.plot_importance(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dm = xgboost.DMatrix(test_data.values[:, 1:])\n",
    "predictions_xgb = model.predict(test_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=test_data.iloc[:, 0], columns=np.round(predictions_xgb), rownames=['actual'], colnames=['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "metrics.accuracy_score(test_data.iloc[:, 0].values, np.round(predictions_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluationスクリプトの作成"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%writefile evaluation.py\n",
    "import os\n",
    "import tarfile\n",
    "import pickle\n",
    "import numpy as np\n",
    "import xgboost\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = os.path.join(\"/opt/ml/processing/model\", \"model.tar.gz\")\n",
    "    print(\"Extracting model from path: {}\".format(model_path))\n",
    "    with tarfile.open(model_path) as tar:\n",
    "        tar.extractall(path=\".\")\n",
    "    print(\"Loading model\")\n",
    "    model = pickle.load(open('xgboost-model', 'rb'))\n",
    "\n",
    "    print(\"Loading test input data\")\n",
    "    test_data = pd.read_csv('test.csv')\n",
    "    dtest = test_data.values\n",
    "    \n",
    "    print(\"Evaluating\")\n",
    "    test_dm = xgboost.DMatrix(test_data.values[:, 1:])\n",
    "    predictions_xgb = model.predict(test_dm)\n",
    "    \n",
    "    score = metrics.accuracy_score(test_data.iloc[:, 0].values, np.round(predictions_xgb))\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalutaion jobの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### processing docker imageの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "# boto3の機能を使ってリポジトリ名に必要な情報を取得する\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = boto3.session.Session().region_name\n",
    "print(region)\n",
    "print(account_id)\n",
    "ecr_repository = 'xgboost-churn-evaluation'\n",
    "tag = ':latest'\n",
    "repository_uri = '{}.dkr.ecr.{}.amazonaws.com/{}'.format(account_id, region, ecr_repository + tag)\n",
    "\n",
    "!$(aws ecr get-login --region $region --registry-ids $account_id --no-include-email)\n",
    "# リポジトリの作成\n",
    "# すでにある場合はこのコマンドは必要ありません。\n",
    "!aws ecr create-repository --repository-name $ecr_repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker build -f Dockerfile-evaluation -t xgboost-churn-evaluation ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker imageをecrにpush\n",
    "!docker tag {ecr_repository + tag} $repository_uri\n",
    "!docker push $repository_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### local からprocessingを実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "role = get_execution_role()\n",
    "\n",
    "script_processor = ScriptProcessor(\n",
    "    image_uri='%s.dkr.ecr.ap-northeast-1.amazonaws.com/%s:latest' % (account_id, ecr_repository),\n",
    "    role=role,\n",
    "    command=['python3'],\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data_s3_uri = model_path\n",
    "\n",
    "script_processor.run(code='evaluation.py',\n",
    "    inputs=[ProcessingInput(\n",
    "            source='test.csv',\n",
    "            destination='/opt/ml/processing/input',\n",
    "            input_name='input-1'),\n",
    "            ProcessingInput(\n",
    "            source=model_data_s3_uri,\n",
    "            destination='/opt/ml/processing/model',\n",
    "            input_name='input-2')],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまでで、SageMaker環境でコンテナを活用した前処理、学習、検証が実行できました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
